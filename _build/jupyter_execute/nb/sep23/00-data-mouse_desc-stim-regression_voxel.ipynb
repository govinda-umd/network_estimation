{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sep 18, 2023: mouse whole brain fMRI, voxel level data: led stimulus regression brain maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp \n",
    "import pickle \n",
    "from os.path import join as pjoin\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# nilearn\n",
    "from nilearn import image\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.cm import rainbow\n",
    "\n",
    "plt.rcParamsDefault['font.family'] = \"sans-serif\"\n",
    "plt.rcParamsDefault['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams[\"errorbar.capsize\"] = 0.5\n",
    "\n",
    "import cmasher as cmr  # CITE ITS PAPER IN YOUR MANUSCRIPT\n",
    "\n",
    "# ignore user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    pass\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "args.subs = np.arange(1, 11)\n",
    "args.sess = np.arange(1, 4)\n",
    "args.num_runs = 7\n",
    "\n",
    "args.num_times = 600\n",
    "args.space_size = [58, 79, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:38, 38.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:39, 51.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:40, 55.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:41, 57.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:40, 58.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [05:41, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [06:43, 60.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [07:51, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [08:35, 56.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [09:28, 55.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [10:31, 57.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [11:19, 54.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [12:21, 57.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [13:17, 56.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [14:19, 58.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [15:15, 57.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [16:15, 58.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [16:57, 53.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [17:40, 50.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [18:42, 53.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3\n",
      "8 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [19:43, 43.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [20:40, 46.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3\n",
      "9 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [21:40, 39.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [22:40, 44.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3\n",
      "10 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [23:40, 38.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [24:41, 43.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [25:40, 51.35s/it]\n"
     ]
    }
   ],
   "source": [
    "stim_path = f'/home/govindas/mouse_dataset/stim'\n",
    "censor_path = f'/home/govindas/mouse_dataset/voxel/frame_censoring_mask'\n",
    "mask_path = f'/home/govindas/mouse_dataset/voxel/commonspace_mask'\n",
    "data_path = f'/home/govindas/mouse_dataset/voxel/cleaned_timeseries'\n",
    "REG_path = f'/home/govindas/mouse_dataset/voxel/regression_analysis'\n",
    "\n",
    "def get_stim(sub, ses):\n",
    "    STIM = [['*'] for _ in range(args.num_runs)]\n",
    "    stim_files = [\n",
    "        f \n",
    "        for f in os.listdir(stim_path)\n",
    "        if f'SLC{sub:02d}' in f\n",
    "        if f'ses-{ses}' in f\n",
    "    ]\n",
    "    # stim_files, STIMS\n",
    "    for stim_file in stim_files:\n",
    "        idx = int([r for r in stim_file.split('_') if 'run' in r][0][-1]) - 1\n",
    "        stim_times = pd.read_csv(f\"{stim_path}/{stim_file}\", index_col=0).dropna()['ledStim1Hz'].values\n",
    "        l = list(np.where(np.diff(stim_times) == 1)[0]+1)\n",
    "        STIM[idx] = l if len(l) > 0 else ['*']\n",
    "    return STIM\n",
    "\n",
    "def get_censor_times(sub, ses, run):\n",
    "    try:\n",
    "        censor_files = [\n",
    "            f \n",
    "            for f in os.listdir(censor_path)\n",
    "            if f'SLC{sub:02d}' in f\n",
    "            if f'ses-{ses}' in f\n",
    "            if f'run-{run}' in f\n",
    "        ]\n",
    "        if len(censor_files) > 0: \n",
    "            censor_file = os.listdir(f'{censor_path}/{censor_files[0]}')[0]\n",
    "            censor_file = f\"{censor_path}/{censor_files[0]}/{censor_file}\"\n",
    "            censor_times = pd.read_csv(censor_file).values.flatten()\n",
    "            return censor_times\n",
    "    except: return None\n",
    "\n",
    "def get_mask(sub, ses, run):\n",
    "    try:\n",
    "        mask_files = [\n",
    "            f \n",
    "            for f in os.listdir(mask_path)\n",
    "            if f'SLC{sub:02d}' in f\n",
    "            if f'ses-{ses}' in f\n",
    "        ]\n",
    "        if len(mask_files) > 0: \n",
    "            mask_run_files = [\n",
    "                f\n",
    "                for f in os.listdir(f'{mask_path}/{mask_files[0]}')\n",
    "                if f'run_{run}' in f\n",
    "            ]\n",
    "            if len(mask_run_files) > 0:\n",
    "                mask_file = os.listdir(f'{mask_path}/{mask_files[0]}/{mask_run_files[0]}')[0]\n",
    "                mask_file = f'{mask_path}/{mask_files[0]}/{mask_run_files[0]}/{mask_file}'\n",
    "                mask = image.load_img(mask_file)\n",
    "                return mask\n",
    "            else: return None\n",
    "    except: return None\n",
    "\n",
    "def get_data(sub, ses, run):\n",
    "    try:\n",
    "        data_files = [\n",
    "            f \n",
    "            for f in os.listdir(data_path)\n",
    "            if f'SLC{sub:02d}' in f\n",
    "            if f'ses-{ses}' in f\n",
    "            if f'run-{run}' in f\n",
    "        ]\n",
    "        if len(data_files) > 0: \n",
    "            data_file = os.listdir(f'{data_path}/{data_files[0]}')[0]\n",
    "            data_file = f'{data_path}/{data_files[0]}/{data_file}'\n",
    "            data = image.load_img(data_file)\n",
    "            return data\n",
    "    except: return None\n",
    "\n",
    "# MAIN LOOP --------\n",
    "for sub, ses in tqdm(product(args.subs, args.sess)):\n",
    "    print(sub, ses)\n",
    "\n",
    "    # stimulus----\n",
    "    STIM = get_stim(sub, ses)\n",
    "\n",
    "    # time series----\n",
    "    keep_runs = []; remove_runs = []\n",
    "    CENSOR = []; DATA = []\n",
    "    cmask_data = np.ones(args.space_size)\n",
    "    for run in np.arange(1, args.num_runs+1):\n",
    "        if STIM[run-1] == ['*']: \n",
    "            remove_runs.append(run)\n",
    "            continue\n",
    "        \n",
    "        censor_times = get_censor_times(sub, ses, run)\n",
    "        mask = get_mask(sub, ses, run)\n",
    "        data = get_data(sub, ses, run)\n",
    "\n",
    "        if not (censor_times is None or mask is None or data is None):\n",
    "            keep_runs.append(run)\n",
    "            t = data.get_fdata()\n",
    "            assert(t.shape[-1] == len(np.where(censor_times)[0]))\n",
    "            ts = np.zeros((args.space_size+[args.num_times]))\n",
    "            ts[:, :, :, np.where(censor_times)[0]] = t\n",
    "            cmask_data *= mask.get_fdata()\n",
    "            CENSOR.append(censor_times)\n",
    "            DATA.append(ts)\n",
    "        else:\n",
    "            remove_runs.append(run)\n",
    "            STIM[run-1] = ['*']\n",
    "            \n",
    "    for run in sorted(remove_runs, reverse=True):\n",
    "        del STIM[run-1]\n",
    "        \n",
    "    # saving----\n",
    "    if len(STIM) == 0: continue\n",
    "    # save CONCAT in a .1D file: per sub and per ses\n",
    "    np.savetxt(\n",
    "        f'{REG_path}/sub-SLC{sub:02d}_ses-{ses}_desc-CONCAT.1D', \n",
    "        np.arange(0, len(STIM)*args.num_times, args.num_times,),\n",
    "        newline=' ', fmt='%d',\n",
    "    )\n",
    "\n",
    "    # save STIMS in a .txt file: per sub and per ses\n",
    "    with open(f'{REG_path}/sub-SLC{sub:02d}_ses-{ses}_desc-STIM.txt', 'w', newline='') as f:\n",
    "        wr = csv.writer(f, delimiter=' ')\n",
    "        wr.writerows(STIM)\n",
    "    \n",
    "    # save space mask in a .nii.gx file: per sub and per ses\n",
    "    image.new_img_like(mask, cmask_data, copy_header=True).to_filename(\n",
    "        f'{REG_path}/sub-SLC{sub:02d}_ses-{ses}_desc-MASK.nii.gz'\n",
    "    )\n",
    "        \n",
    "    # save DATA in a .1D file: per sub and per ses\n",
    "    image.new_img_like(\n",
    "        data, \n",
    "        np.nan_to_num(np.concatenate(DATA, axis=-1)),\n",
    "        copy_header=True\n",
    "    ).to_filename(\n",
    "        f'{REG_path}/sub-SLC{sub:02d}_ses-{ses}_desc-INPUT.nii.gz'\n",
    "    )\n",
    "    \n",
    "    # save CENSOR in a .txt file: per sub and per ses\n",
    "    CENSOR = np.nan_to_num(np.hstack(CENSOR))\n",
    "    np.savetxt(f'{REG_path}/sub-SLC{sub:02d}_ses-{ses}_desc-CENSOR.txt', CENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub, ses = 1, 1\n",
    "# mask = image.load_img(f'{REG_path}/sub-SLC{sub:02d}_ses-{ses}_desc-MASK.nii.gz').get_fdata()\n",
    "# temp = image.load_img('/home/govindas/mouse_dataset/voxel/regression_analysis/Symmetric_N162_0.20_permuted.nii.gz').get_fdata()\n",
    "# mask.shape, temp.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nw_estim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}