{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oct 12-15,21, 2023: estimate functional networks: runwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp \n",
    "import pickle \n",
    "from os.path import join as pjoin\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from scipy import sparse, stats\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# networks\n",
    "import networkx as nx\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.cm import rainbow\n",
    "\n",
    "plt.rcParamsDefault['font.family'] = \"sans-serif\"\n",
    "plt.rcParamsDefault['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams[\"errorbar.capsize\"] = 0.5\n",
    "\n",
    "import cmasher as cmr  # CITE ITS PAPER IN YOUR MANUSCRIPT\n",
    "\n",
    "# ignore user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #, category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    pass\n",
    "\n",
    "args = ARGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.parcel_name = 'whole'\n",
    "BASE_path = f'/home/govindas/mouse_dataset/roi'\n",
    "TS_path = f'{BASE_path}/roi_timeseries_txt_files/{args.parcel_name}'\n",
    "FC_path = f'{BASE_path}/func_nws_files/{args.parcel_name}'\n",
    "cmd = (\n",
    "    f'mkdir -p {FC_path}'\n",
    ")\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runwise FCs \n",
    "args.num_subs = 10\n",
    "args.num_sess = 3\n",
    "args.num_rois = len(np.loadtxt(\n",
    "        (\n",
    "            f'/home/govindas/mouse_dataset/allen_atlas_ccfv3/hadi/parcellation'\n",
    "            f'/warped_on_n162/{args.parcel_name}_roi_labels.txt'\n",
    "        )\n",
    "    ).astype(int)\n",
    ")\n",
    "args.percentile = 90\n",
    "main_sample = [\n",
    "    [\n",
    "        []\n",
    "        for ses in range(args.num_sess)\n",
    "    ]\n",
    "    for sub in range(args.num_subs)\n",
    "]\n",
    "for file in os.listdir(TS_path):\n",
    "    fs = file.split('_')\n",
    "    if int(fs[2].split('-')[-1]) % 2 == 0: continue # skip even runs\n",
    "    sub = int(fs[0].split('-')[-1][-2:])\n",
    "    ses = int(fs[1].split('-')[-1])\n",
    "    # run = int(fs[2].split('-')[-1])\n",
    "    main_sample[sub-1][ses-1].append(file)\n",
    "\n",
    "for sub in np.arange(1,args.num_subs+1):\n",
    "    for ses in np.arange(1, args.num_sess+1):\n",
    "        main_sample[sub-1][ses-1] = list(np.sort(main_sample[sub-1][ses-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.num_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:34,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "fcs = [\n",
    "    [\n",
    "        []\n",
    "        for ses in range(args.num_sess)\n",
    "    ]\n",
    "    for sub in range(args.num_subs)\n",
    "]\n",
    "for sub, ses in tqdm(product(range(args.num_subs), range(args.num_sess))):\n",
    "    for run in main_sample[sub][ses]:\n",
    "        ts = np.loadtxt(f'{TS_path}/{run}')\n",
    "        ts = stats.zscore(ts, axis=0, nan_policy='omit')\n",
    "        fc = np.corrcoef(ts, rowvar=False)\n",
    "        fc = fc[np.tril_indices(fc.shape[0], k=-1)]\n",
    "        fc[np.isnan(fc)] = 0.0\n",
    "        fc = fc > np.percentile(fc, q=args.percentile) # keep only top 10% edges, this removes neg. edges\n",
    "        \n",
    "        fc_ = np.zeros((args.num_rois, args.num_rois))\n",
    "        fc_[np.tril_indices(fc_.shape[0], k=-1)] = fc\n",
    "        fc_ = (fc_ + fc_.T)\n",
    "        \n",
    "        fcs[sub][ses].append(fc_)\n",
    "        \n",
    "        edges = np.stack(np.where(np.tril(fc_, k=-1)), axis=-1)\n",
    "        nw_edges_file = '_'.join(run.split('_')[:-1] + ['desc-nw-edges.txt'])\n",
    "        with open(f'{FC_path}/{nw_edges_file}', 'w', newline='') as f:\n",
    "            wr = csv.writer(f, delimiter='\\t')\n",
    "            wr.writerows(edges)\n",
    "            \n",
    "with open(f'{BASE_path}/npy_files/func_nws_{args.parcel_name}.npy', 'wb') as f:\n",
    "    pickle.dump(fcs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nw_estim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
