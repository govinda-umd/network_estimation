{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feb 26, 2023: copy Hadi's columnar brain parcellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "from allensdk.core.mouse_connectivity_cache import (\n",
    "    MouseConnectivityCache,\n",
    "    MouseConnectivityApi\n",
    ")\n",
    "\n",
    "import glob \n",
    "\n",
    "import ants\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrois = 192 #512 # 192 # 128\n",
    "# do the following in terminal:\n",
    "# cd ~/mouse_dataset/allen_atlas_ccfv3/hadi/parcellation\n",
    "# scp -r lceuser@kaba.umd.edu:/home/hadi/Documents/Ca-fMRI/processed/norm-global_parcel-columnar_n-192\\*3/parcellation ./parcellation_n-192*3/\n",
    "# scp -r lceuser@kaba.umd.edu:/home/hadi/Documents/Ca-fMRI/processed/norm-global_parcel-columnar_n-192\\*3/roi_lookup.npy ./parcellation_n-192*3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    pass\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "args.SEED = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_path = f'{os.environ[\"HOME\"]}/mouse_dataset'\n",
    "HADI_PARCELS_path = f'{BASE_path}/allen_atlas_ccfv3/hadi/parcellation/parcellation_n-{nrois}*3'\n",
    "PARCELS_path = f'{BASE_path}/parcels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 80, 114)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_parcels = np.load(f'{HADI_PARCELS_path}/brain_100um.npy')\n",
    "h_parcels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1150, 1151, 1152], dtype=uint32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_parcels_ctx = np.load(f'{HADI_PARCELS_path}/cortex_100um.npy')\n",
    "np.unique(h_parcels_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_lookup = np.load(f'{HADI_PARCELS_path}/roi_lookup.npy', allow_pickle=True).item()\n",
    "len(roi_lookup['ca2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole brain\n",
    "parcels_whl = h_parcels\n",
    "\n",
    "# cortex\n",
    "parcels_ctx = np.zeros_like(h_parcels, dtype=np.int64)\n",
    "\n",
    "# calcium parcels\n",
    "parcels_ca2 = np.zeros_like(h_parcels, dtype=np.int64)\n",
    "for roi in roi_lookup['ca2'].values():\n",
    "    parcels_ca2 += (h_parcels == roi) * roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nifti(args, img, print_=True):\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = img[:,:,::-1]\n",
    "    img = np.pad(\n",
    "        img, \n",
    "        pad_width=((2, 2), (4, 24), (8, 2)), \n",
    "        mode='constant',\n",
    "        constant_values=((0, 0), (0, 0), (0, 0))\n",
    "        )\n",
    "    if print_: print(img.dtype, img.shape)\n",
    "    ndims = len(img.shape)\n",
    "    ants_img = ants.from_numpy(\n",
    "        data=img.astype(np.float32), \n",
    "        origin=[6.4, -13.2, -7.8],\n",
    "        spacing=[0.1]*ndims,\n",
    "    )\n",
    "    return ants_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 80, 114) (132, 80, 114)\n"
     ]
    }
   ],
   "source": [
    "args.atlas_path = f'{os.environ[\"HOME\"]}/mouse_dataset/allen_atlas_ccfv3'\n",
    "args.mcc_path = f'{args.atlas_path}/MouseConnectivity'\n",
    "mcc = MouseConnectivityCache(\n",
    "    resolution=100, # in micro meters (um)\n",
    "    ccf_version=MouseConnectivityApi().CCF_2017,\n",
    "    manifest_file=f'{args.mcc_path}/manifest.json',\n",
    ")\n",
    "AVGT, metaAVGT = mcc.get_template_volume()\n",
    "ANO, metaANO = mcc.get_annotation_volume()\n",
    "AVGT = AVGT.astype(np.float32)\n",
    "ANO = ANO.astype(np.uint32)\n",
    "print(AVGT.shape, ANO.shape)\n",
    "\n",
    "STree = mcc.get_structure_tree()\n",
    "STree_df = pd.DataFrame(STree.nodes()) \n",
    "# for idx in STree_df.id.to_list():\n",
    "#     try: \n",
    "#         mcc.get_structure_mask(structure_id=idx) \n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (118, 160, 90)\n",
      "float32 (118, 160, 90)\n"
     ]
    }
   ],
   "source": [
    "# templates in nifti\n",
    "n162_100um_template = f'{os.environ[\"HOME\"]}/mouse_dataset/gabe_symmetric_N162/Symmetric_N162_0.10_RAS.nii.gz'\n",
    "n162_100um_template = ants.image_read(n162_100um_template)\n",
    "print(n162_100um_template.numpy().dtype, n162_100um_template.numpy().shape)\n",
    "\n",
    "allen_template = to_nifti(args, AVGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducible registration\n",
    "os.system('export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=1')\n",
    "os.system('export ANTS_RANDOM_SEED=1')\n",
    "\n",
    "tx = ants.registration(\n",
    "    fixed=n162_100um_template,\n",
    "    moving=allen_template,\n",
    "    type_of_transform=('SyN'),\n",
    "    random_seed=args.SEED,\n",
    ")\n",
    "\n",
    "def transform(args, img):\n",
    "    img_tx = ants.apply_transforms(\n",
    "        fixed=n162_100um_template,\n",
    "        moving=img,\n",
    "        transformlist=tx['fwdtransforms'],\n",
    "        interpolator='genericLabel',\n",
    "    )\n",
    "    return img_tx\n",
    "    \n",
    "allen_template_tx = transform(args, img=allen_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 81, 46)\n"
     ]
    }
   ],
   "source": [
    "# resampling to 0.2mm resolution\n",
    "n162_200um_template = f'{os.environ[\"HOME\"]}/mouse_dataset/gabe_symmetric_N162/Symmetric_N162_0.20_RAS.nii.gz'\n",
    "n162_200um_template = ants.image_read(n162_200um_template)\n",
    "\n",
    "def resample(args, target, img):\n",
    "    img_rs = ants.resample_image_to_target(\n",
    "        image=img,\n",
    "        target=target,\n",
    "        interp_type='genericLabel',\n",
    "    )\n",
    "    img_rs = img_rs.new_image_like(\n",
    "        data=img_rs.numpy() * (target.numpy() > 0)\n",
    "    )\n",
    "    print(img_rs.numpy().shape)\n",
    "    return img_rs\n",
    "    \n",
    "allen_template_tx_rs = resample(args, target=n162_200um_template, img=allen_template_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [00:00, 257.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# common brain mask (across subs)\n",
    "BASE_path = f'{os.environ[\"HOME\"]}/mouse_dataset'\n",
    "all_files_path = f'{BASE_path}/voxel/all_file_collections'\n",
    "all_files = os.listdir(all_files_path)\n",
    "\n",
    "# cmask : common brain mask\n",
    "for idx, files in tqdm(enumerate(all_files[:])):\n",
    "    if idx == 0:\n",
    "        with open(f'{all_files_path}/{files}', 'r') as f:\n",
    "            cmask_img = ants.image_read(f.readlines()[1][:-1])\n",
    "        cmask = cmask_img.numpy()\n",
    "    else:\n",
    "        with open(f'{all_files_path}/{files}', 'r') as f:\n",
    "            cmask *= ants.image_read(f.readlines()[1][:-1]).numpy()\n",
    "cmask_img = cmask_img.new_image_like(cmask)\n",
    "cmask_img.to_filename(\n",
    "    f'{BASE_path}/voxel/common_brain_mask.nii.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_parcels(args, parcels,):\n",
    "    # all transformations\n",
    "    parcels_img = to_nifti(args, parcels)\n",
    "    parcels_img_tx = transform(args, img=parcels_img)\n",
    "    parcels_img_tx_rs = resample(args, target=n162_200um_template, img=parcels_img_tx)\n",
    "    parcels_img_tx_rs_cm = resample(args, target=cmask_img, img=parcels_img_tx_rs)\n",
    "    \n",
    "    # description of the parcellation\n",
    "    args.num_rois = len(np.unique(parcels_img_tx_rs_cm.numpy())[1:])\n",
    "    DESC = (\n",
    "        f'type-{args.type}'\n",
    "        f'_size-{args.roi_size}'\n",
    "        f'_symm-{args.maintain_symmetry}'\n",
    "        f'_braindiv-{args.brain_div}'\n",
    "        f'_nrois-{args.num_rois}'\n",
    "    )\n",
    "    parcels_file = f'{PARCELS_path}/{DESC}_desc-parcels.nii.gz'\n",
    "    labels_file = f'{PARCELS_path}/{DESC}_desc-labels.txt'\n",
    "    \n",
    "    # save\n",
    "    parcels_img_tx_rs_cm.to_filename(parcels_file)\n",
    "    \n",
    "    # roi labels\n",
    "    cmd = (\n",
    "        f'3dROIstats -overwrite '\n",
    "        f'-quiet '\n",
    "        f'-mask {parcels_file} '\n",
    "        f'{parcels_file} > {labels_file}'\n",
    "    )\n",
    "    os.system(cmd)\n",
    "\n",
    "    # done\n",
    "    return parcels_img_tx_rs_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.type = 'columnar'\n",
    "# args.roi_size = 'x'\n",
    "# args.maintain_symmetry = True\n",
    "# args.brain_div = 'whl'\n",
    "# parcels_whl_img_tx_rs_cm = transform_parcels(args, parcels_whl,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 (118, 160, 90)\n",
      "(60, 81, 46)\n",
      "(58, 79, 45)\n"
     ]
    }
   ],
   "source": [
    "args.type = 'columnar'\n",
    "args.roi_size = 'x'\n",
    "args.maintain_symmetry = True\n",
    "args.brain_div = 'ca2'\n",
    "parcels_ca2_img_tx_rs_cm = transform_parcels(args, parcels_ca2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~/mouse_dataset/allen_atlas_ccfv3/hadi/parcellation/parcellation_n-192*3\n",
    "# mkdir -p bold\n",
    "# cd bold\n",
    "# scp -r lceuser@kaba.umd.edu:/home/hadi/Documents/Ca-fMRI/processed/norm-global_parcel-columnar_n-192*3/bold/*task-rest*rabies-hp* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.unique(parcels_ca2)[1:] == np.array(list(roi_lookup['ca2'].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca2 = roi_lookup['ca2']\n",
    "k, v = list(ca2.keys()), list(ca2.values())\n",
    "ca2_df = pd.DataFrame({\n",
    "    'idx':k, \n",
    "    'roi':v\n",
    "}).reset_index(drop=True)\n",
    "# ca2_df\n",
    "\n",
    "bold = roi_lookup['bold']\n",
    "k, v = list(bold.keys()), list(bold.values())\n",
    "bold_df = pd.DataFrame({\n",
    "    'idx':k, \n",
    "    'roi':v,\n",
    "}).reset_index(drop=True)\n",
    "# bold_df\n",
    "\n",
    "roi_idxs = bold_df[bold_df['roi'].isin(ca2_df['roi'].to_list())]['idx'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_path = f'{BASE_path}/roi'\n",
    "DESC = (\n",
    "    f'type-{args.type}'\n",
    "    f'_size-{args.roi_size}'\n",
    "    f'_symm-{args.maintain_symmetry}'\n",
    "    f'_braindiv-{args.brain_div}'\n",
    "    f'_nrois-{args.num_rois}'\n",
    ")\n",
    "TS_path = f'{TS_path}/{DESC}/roi_timeseries'\n",
    "os.system(f'mkdir -p {TS_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_files = glob.glob(f'{HADI_PARCELS_path}/bold/*', recursive=True)\n",
    "for bold_file in bold_files:\n",
    "    ts_file = '_'.join(bold_file.split('/')[-1].split('_')[:4] + [f'desc-roi-ts.txt'])\n",
    "    bold_ts = np.load(bold_file)[roi_idxs, :].T\n",
    "    np.savetxt(\n",
    "        f'{TS_path}/{ts_file}',\n",
    "        bold_ts,\n",
    "        fmt='%.3e',\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nw_estim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
