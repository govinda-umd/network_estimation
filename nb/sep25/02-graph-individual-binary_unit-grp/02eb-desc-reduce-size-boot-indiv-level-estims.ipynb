{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sep 19, 2025: reduce size of bootstrap estimates\n",
    "sample 1000 partitions in total from the modes made from 15,000 partitions\n",
    "\n",
    "conda env: gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp \n",
    "import dill as pickle \n",
    "from scipy import stats\n",
    "from os.path import join as pjoin\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from itertools import product, combinations\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from munkres import Munkres\n",
    "\n",
    "# networks\n",
    "import graph_tool.all as gt\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.cm import rainbow\n",
    "\n",
    "plt.rcParamsDefault['font.family'] = \"sans-serif\"\n",
    "plt.rcParamsDefault['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams[\"errorbar.capsize\"] = 0.5\n",
    "\n",
    "import colorcet as cc\n",
    "\n",
    "# ignore user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #, category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    pass\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "args.SEED = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source-allen_space-ccfv2_braindiv-whl_nrois-172_res-200'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.source = 'allen' #'spatial' #'allen'\n",
    "args.space = 'ccfv2' #'ccfv2'\n",
    "args.brain_div = 'whl' #'whl'\n",
    "args.num_rois = 172 #162 #172\n",
    "args.resolution = 200 #200\n",
    "\n",
    "PARC_DESC = (\n",
    "    f'source-{args.source}'\n",
    "    f'_space-{args.space}'\n",
    "    f'_braindiv-{args.brain_div}'\n",
    "    f'_nrois-{args.num_rois}'\n",
    "    f'_res-{args.resolution}'\n",
    ")\n",
    "PARC_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.GRAPH_DEF = f'constructed'\n",
    "args.GRAPH_METHOD = f'pearson'\n",
    "args.THRESHOLD = f'signed'\n",
    "args.EDGE_DEF = f'binary'\n",
    "args.EDGE_DENSITY = 20\n",
    "args.LAYER_DEF = f'individual'\n",
    "args.DATA_UNIT = f'grp-boot'\n",
    "\n",
    "BASE_path = f'{os.environ[\"HOME\"]}/new_mouse_dataset'\n",
    "PARCELS_path = f'{BASE_path}/parcels'\n",
    "ROI_path = (\n",
    "    f'{BASE_path}/roi-results-v3'\n",
    "    f'/{PARC_DESC}'\n",
    ")\n",
    "TS_path = f'{ROI_path}/roi_timeseries'\n",
    "ROI_RESULTS_path = (\n",
    "    f'{ROI_path}'\n",
    "    f'/graph-{args.GRAPH_DEF}/method-{args.GRAPH_METHOD}'\n",
    "    f'/threshold-{args.THRESHOLD}/edge-{args.EDGE_DEF}/density-{args.EDGE_DENSITY}'\n",
    "    f'/layer-{args.LAYER_DEF}/unit-{args.DATA_UNIT}'\n",
    ")\n",
    "GRAPH_path = f'{ROI_RESULTS_path}/graphs'\n",
    "os.system(f'mkdir -p {GRAPH_path}')\n",
    "SBM_path = f'{ROI_RESULTS_path}/model-fits'\n",
    "os.system(f'mkdir -p {SBM_path}')\n",
    "DIAG_path = f'{ROI_RESULTS_path}/diagnostics'\n",
    "os.system(f'mkdir -p {DIAG_path}')\n",
    "ESTIM_path = f'{ROI_RESULTS_path}/estimates'\n",
    "os.system(f'mkdir -p {ESTIM_path}/individual')\n",
    "os.system(f'mkdir -p {ESTIM_path}/group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sbm-nd-d'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.dc, args.sbm = False, 'd'\n",
    "args.nested = args.sbm == 'h'\n",
    "\n",
    "args.force_niter = 100000\n",
    "args.num_draws = int((1/2) * args.force_niter)\n",
    "\n",
    "args.epsilon = 0.4 # threshold KSD for convergence\n",
    "args.delta = np.ceil(args.force_niter / 100).astype(int)\n",
    "\n",
    "def sbm_name(args):\n",
    "    dc = f'dc' if args.dc else f'nd'\n",
    "    dc = f'' if args.sbm in ['a', 'm'] else dc\n",
    "    file = f'sbm-{dc}-{args.sbm}'\n",
    "    return file\n",
    "\n",
    "SBM = sbm_name(args)\n",
    "SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph object, undirected, with 172 vertices and 2942 edges, 1 internal edge property, at 0x7efb5d665e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile = sorted(glob.glob(f'{GRAPH_path}/*', recursive=True))[0]\n",
    "g = gt.load_graph(gfile)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_partitions(args, indests_df):\n",
    "    all_bs_df = []\n",
    "    for idx, row in tqdm(indests_df.iterrows()):\n",
    "        bs = random.sample(\n",
    "            list(row['mode'].get_partitions().values()), \n",
    "            row['num_samples']\n",
    "        )\n",
    "        df = pd.DataFrame(dict(\n",
    "            boot=[row['boot']]*len(bs),\n",
    "            mode_id=[idx]*len(bs),\n",
    "            b=bs,\n",
    "        ))\n",
    "        all_bs_df += [df]\n",
    "        # all_bs += [\n",
    "        #   row['mode'].sample_partition(MLE=True) \n",
    "        #   for _ in range(row['num_samples'])\n",
    "        # ]\n",
    "    all_bs_df = pd.concat(all_bs_df).reset_index(drop=True)\n",
    "    return all_bs_df\n",
    "\n",
    "def sample_nested_partitions(args, indests_df):\n",
    "    all_bs_df = []\n",
    "    for idx, row in tqdm(indests_df.iterrows()):\n",
    "        bs = random.sample(\n",
    "            list(row['mode'].get_nested_partitions().values()), \n",
    "            row['num_samples']\n",
    "        )\n",
    "        # bs = [gt.nested_partition_clear_null(b) for b in bs]\n",
    "        df = pd.DataFrame(dict(\n",
    "            boot=[row['boot']]*len(bs),\n",
    "            mode_id=[idx]*len(bs),\n",
    "            b=bs,\n",
    "        ))\n",
    "        all_bs_df += [df]\n",
    "        # all_bs += [\n",
    "        #   row['mode'].sample_partition(MLE=True) \n",
    "        #   for _ in range(row['num_samples'])\n",
    "        # ]\n",
    "    all_bs_df = pd.concat(all_bs_df).reset_index(drop=True)\n",
    "    return all_bs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduced_indiv_estim(args, indiv_file):\n",
    "    try:\n",
    "        # load individual estimates\n",
    "        with open(indiv_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "            \n",
    "        # make output folder\n",
    "        match = re.search(r'boot-(\\d+)', indiv_file)\n",
    "        if match: boot,  = match.groups()\n",
    "        red_indiv_path = f'{ESTIM_path}/individual/boot-{boot}/partition-modes-reduced'\n",
    "        os.makedirs(red_indiv_path, exist_ok=True)\n",
    "\n",
    "        # sample partitions per mode\n",
    "        args.total_samples = 1000\n",
    "        df['num_samples'] = df['omega'].apply(lambda x: np.round(x * args.total_samples).astype(int) if x > 0.01 else 1)\n",
    "        if args.sbm in ['m', 'a', 'd']:\n",
    "            all_bs_df = sample_partitions(args, df)\n",
    "        if args.sbm in ['h']:\n",
    "            all_bs_df = sample_nested_partitions(args, df)\n",
    "            \n",
    "        # create the indiv_estim_df\n",
    "        red_df = []\n",
    "        for mode_id, group in all_bs_df.groupby('mode_id'):\n",
    "            mode = gt.PartitionModeState(group['b'], relabel=False, nested=args.nested, converge=False)\n",
    "            r = df[df['mode_id'] == mode_id].reset_index(drop=True)\n",
    "            row = pd.DataFrame(dict(\n",
    "                boot=[r['boot'][0]],\n",
    "                sbm=[r['sbm'][0]],\n",
    "                mode_id=[mode_id],\n",
    "                mode=[mode],\n",
    "                omega=[r['omega'][0]],\n",
    "                sigma=[r['sigma'][0]],\n",
    "            ))\n",
    "            red_df += [row]\n",
    "            # break\n",
    "        red_df = pd.concat(red_df).reset_index(drop=True)\n",
    "\n",
    "        # save the df\n",
    "        with open(f'{red_indiv_path}/{SBM}_desc-df.pkl', 'wb') as f:\n",
    "            pickle.dump(red_df, f)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "indiv_files = sorted(glob.glob(f'{ESTIM_path}/individual/boot-*/partition-modes/{SBM}_desc-df.pkl'))\n",
    "len(indiv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 298.49it/s]\n",
      "5it [00:00, 100.36it/s]\n",
      "7it [00:00, 139.90it/s]\n",
      "12it [00:00, 271.67it/s]\n",
      "15it [00:00, 229.54it/s]\n",
      "16it [00:00, 356.78it/s]\n",
      "7it [00:00, 143.50it/s]\n",
      "4it [00:00, 79.04it/s]\n",
      "6it [00:00, 114.08it/s]\n",
      "2it [00:00, 37.40it/s]\n",
      "9it [00:00, 198.32it/s]\n",
      "4it [00:00, 79.58it/s]\n",
      "6it [00:00, 113.10it/s]\n",
      "9it [00:00, 173.42it/s]\n",
      "13it [00:00, 281.57it/s]\n",
      "10it [00:00, 202.30it/s]\n",
      "17it [00:00, 371.59it/s]\n",
      "5it [00:00, 96.95it/s]\n",
      "5it [00:00, 101.65it/s]\n",
      "11it [00:00, 229.22it/s]\n",
      "7it [00:00, 132.85it/s]\n",
      "12it [00:00, 243.08it/s]\n",
      "9it [00:00, 144.20it/s]\n",
      "10it [00:00, 212.26it/s]\n",
      "3it [00:00, 58.29it/s]\n",
      "4it [00:00, 76.87it/s]\n",
      "10it [00:00, 210.11it/s]\n",
      "7it [00:00, 136.10it/s]\n",
      "6it [00:00, 114.13it/s]\n",
      "15it [00:00, 314.69it/s]\n",
      "7it [00:00, 143.06it/s]\n",
      "4it [00:00, 76.31it/s]\n",
      "10it [00:00, 209.91it/s]\n",
      "5it [00:00, 104.28it/s]\n",
      "6it [00:00, 116.72it/s]\n",
      "5it [00:00, 98.21it/s]\n",
      "5it [00:00, 107.76it/s]\n",
      "3it [00:00, 58.10it/s]\n",
      "11it [00:00, 233.91it/s]\n",
      "14it [00:00, 293.25it/s]\n",
      "10it [00:00, 212.40it/s]\n",
      "8it [00:00, 171.44it/s]\n",
      "12it [00:00, 248.77it/s]\n",
      "11it [00:00, 234.76it/s]\n",
      "8it [00:00, 161.92it/s]\n",
      "4it [00:00, 72.18it/s]\n",
      "11it [00:00, 213.76it/s]\n",
      "9it [00:00, 188.13it/s]\n",
      "17it [00:00, 119.80it/s]\n",
      "14it [00:00, 311.81it/s]\n",
      "7it [00:00, 143.64it/s]\n",
      "13it [00:00, 278.98it/s]\n",
      "7it [00:00, 146.13it/s]\n",
      "5it [00:00, 96.96it/s]\n",
      "8it [00:00, 143.87it/s]\n",
      "9it [00:00, 192.92it/s]\n",
      "18it [00:00, 393.28it/s]\n",
      "9it [00:00, 163.51it/s]\n",
      "7it [00:00, 126.26it/s]\n",
      "7it [00:00, 144.42it/s]\n",
      "11it [00:00, 242.39it/s]\n",
      "5it [00:00, 104.81it/s]\n",
      "6it [00:00, 122.42it/s]\n",
      "21it [00:00, 458.87it/s]\n",
      "5it [00:00, 97.70it/s]\n",
      "5it [00:00, 102.60it/s]\n",
      "12it [00:00, 239.12it/s]\n",
      "5it [00:00, 101.37it/s]\n",
      "16it [00:00, 351.64it/s]\n",
      "6it [00:00, 114.63it/s]\n",
      "9it [00:00, 188.06it/s]\n",
      "2it [00:00, 39.09it/s]\n",
      "8it [00:00, 204.43it/s]\n",
      "12it [00:00, 260.13it/s]\n",
      "6it [00:00, 117.33it/s]\n",
      "12it [00:00, 247.35it/s]\n",
      "8it [00:00, 169.75it/s]\n",
      "6it [00:00, 101.75it/s]\n",
      "10it [00:00, 212.68it/s]\n",
      "8it [00:00, 173.01it/s]\n",
      "8it [00:00, 176.15it/s]\n",
      "8it [00:00, 166.80it/s]\n",
      "9it [00:00, 185.97it/s]\n",
      "12it [00:00, 258.74it/s]\n",
      "11it [00:00, 81.34it/s]\n",
      "10it [00:00, 208.47it/s]\n",
      "7it [00:00, 139.76it/s]\n",
      "14it [00:00, 294.01it/s]\n",
      "5it [00:00, 96.27it/s]\n",
      "8it [00:00, 165.29it/s]\n",
      "13it [00:00, 277.32it/s]\n",
      "8it [00:00, 170.80it/s]\n",
      "23it [00:00, 526.17it/s]\n",
      "11it [00:00, 246.02it/s]\n",
      "13it [00:00, 281.21it/s]\n",
      "9it [00:00, 178.22it/s]\n",
      "10it [00:00, 214.33it/s]\n",
      "6it [00:00, 122.02it/s]\n",
      "10it [00:00, 209.37it/s]\n",
      "8it [00:00, 165.33it/s]\n",
      "19it [00:00, 436.03it/s]\n",
      "10it [00:00, 70.01it/s]\n",
      "16it [00:00, 357.13it/s]\n",
      "6it [00:00, 126.25it/s]\n",
      "5it [00:00, 99.29it/s]\n",
      "10it [00:00, 198.58it/s]\n",
      "8it [00:00, 153.58it/s]\n",
      "9it [00:00, 171.99it/s]\n",
      "14it [00:00, 281.77it/s]\n",
      "13it [00:00, 281.77it/s]\n",
      "5it [00:00, 103.25it/s]\n",
      "5it [00:00, 95.86it/s]\n",
      "7it [00:00, 146.56it/s]\n",
      "1it [00:00, 18.45it/s]\n",
      "10it [00:00, 207.65it/s]\n",
      "7it [00:00, 141.11it/s]\n",
      "3it [00:00, 58.72it/s]\n",
      "7it [00:00, 135.93it/s]\n",
      "8it [00:00, 171.85it/s]\n",
      "9it [00:00, 178.59it/s]\n",
      "6it [00:00, 124.49it/s]\n",
      "8it [00:00, 159.14it/s]\n",
      "7it [00:00, 139.49it/s]\n",
      "4it [00:00, 83.19it/s]\n",
      "5it [00:00, 100.59it/s]\n",
      "4it [00:00, 79.78it/s]\n",
      "11it [00:00, 232.18it/s]\n",
      "15it [00:00, 330.98it/s]\n",
      "11it [00:00, 233.55it/s]\n",
      "13it [00:00, 277.96it/s]\n",
      "12it [00:00, 259.71it/s]\n",
      "6it [00:00, 121.46it/s]\n",
      "12it [00:00, 253.89it/s]\n",
      "6it [00:00, 86.70it/s]\n",
      "10it [00:00, 71.03it/s]\n",
      "6it [00:00, 120.16it/s]\n",
      "6it [00:00, 121.25it/s]\n",
      "7it [00:00, 142.51it/s]\n",
      "9it [00:00, 191.54it/s]\n",
      "14it [00:00, 303.33it/s]\n",
      "8it [00:00, 161.02it/s]\n",
      "15it [00:00, 336.41it/s]\n",
      "7it [00:00, 151.91it/s]\n",
      "13it [00:00, 275.96it/s]\n",
      "8it [00:00, 153.17it/s]\n",
      "5it [00:00, 97.86it/s]\n",
      "14it [00:00, 309.59it/s]\n",
      "11it [00:00, 225.62it/s]\n",
      "7it [00:00, 141.10it/s]\n",
      "11it [00:00, 241.13it/s]\n",
      "8it [00:00, 163.11it/s]\n",
      "7it [00:00, 130.01it/s]\n",
      "11it [00:00, 232.69it/s]\n",
      "13it [00:00, 287.56it/s]\n",
      "10it [00:00, 209.34it/s]\n",
      "6it [00:00, 121.16it/s]\n",
      "4it [00:00, 81.06it/s]\n",
      "7it [00:00, 150.21it/s]\n",
      "13it [00:00, 283.86it/s]\n",
      "14it [00:00, 305.96it/s]\n",
      "3it [00:00, 60.89it/s]\n",
      "8it [00:00, 161.04it/s]\n",
      "8it [00:00, 160.05it/s]\n",
      "4it [00:00, 83.68it/s]\n",
      "11it [00:00, 234.93it/s]\n",
      "2it [00:00, 38.54it/s]\n",
      "12it [00:00, 250.55it/s]\n",
      "8it [00:00, 168.00it/s]\n",
      "9it [00:00, 188.64it/s]\n",
      "8it [00:00, 172.48it/s]\n",
      "10it [00:00, 206.13it/s]\n",
      "10it [00:00, 206.79it/s]\n",
      "13it [00:00, 281.05it/s]\n",
      "12it [00:00, 251.01it/s]\n",
      "6it [00:00, 117.36it/s]\n",
      "6it [00:00, 120.78it/s]\n",
      "12it [00:00, 262.11it/s]\n",
      "8it [00:00, 164.77it/s]\n",
      "12it [00:00, 265.04it/s]\n",
      "14it [00:00, 312.33it/s]\n",
      "9it [00:00, 182.84it/s]\n",
      "9it [00:00, 188.28it/s]\n",
      "2it [00:00, 37.41it/s]\n",
      "17it [00:00, 127.43it/s]\n",
      "11it [00:00, 234.86it/s]\n",
      "16it [00:00, 359.72it/s]\n",
      "8it [00:00, 163.26it/s]\n",
      "10it [00:00, 213.16it/s]\n",
      "4it [00:00, 80.31it/s]\n",
      "9it [00:00, 184.47it/s]\n",
      "7it [00:00, 140.22it/s]\n",
      "5it [00:00, 99.09it/s]\n",
      "14it [00:00, 313.35it/s]\n",
      "12it [00:00, 262.95it/s]\n",
      "10it [00:00, 214.94it/s]\n",
      "12it [00:00, 236.57it/s]\n",
      "9it [00:00, 193.32it/s]\n",
      "6it [00:00, 118.83it/s]\n",
      "9it [00:00, 183.78it/s]\n",
      "6it [00:00, 127.24it/s]\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=10)(\n",
    "    delayed(create_reduced_indiv_estim)(args, indiv_file) \n",
    "    for indiv_file in (indiv_files)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
