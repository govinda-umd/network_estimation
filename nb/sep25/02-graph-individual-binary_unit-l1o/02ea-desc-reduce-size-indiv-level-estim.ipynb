{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aug 24, Sep 19, 2025: reduce size of estimates\n",
    "sample 1000 partitions in total from the modes made from 15,000 partitions\n",
    "\n",
    "conda env: gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp \n",
    "import dill as pickle \n",
    "from scipy import stats\n",
    "from os.path import join as pjoin\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from itertools import product, combinations\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from munkres import Munkres\n",
    "\n",
    "# networks\n",
    "import graph_tool.all as gt\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.cm import rainbow\n",
    "\n",
    "plt.rcParamsDefault['font.family'] = \"sans-serif\"\n",
    "plt.rcParamsDefault['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams[\"errorbar.capsize\"] = 0.5\n",
    "\n",
    "import colorcet as cc\n",
    "\n",
    "# ignore user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #, category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    pass\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "args.SEED = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source-allen_space-ccfv2_braindiv-whl_nrois-172_res-200'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.source = 'allen' #'spatial' #'allen'\n",
    "args.space = 'ccfv2' #'ccfv2'\n",
    "args.brain_div = 'whl' #'whl'\n",
    "args.num_rois = 172 #162 #172\n",
    "args.resolution = 200 #200\n",
    "\n",
    "PARC_DESC = (\n",
    "    f'source-{args.source}'\n",
    "    f'_space-{args.space}'\n",
    "    f'_braindiv-{args.brain_div}'\n",
    "    f'_nrois-{args.num_rois}'\n",
    "    f'_res-{args.resolution}'\n",
    ")\n",
    "PARC_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.GRAPH_DEF = f'constructed'\n",
    "args.GRAPH_METHOD = f'pearson'\n",
    "args.THRESHOLD = f'signed'\n",
    "args.EDGE_DEF = f'binary'\n",
    "args.EDGE_DENSITY = 20\n",
    "args.LAYER_DEF = f'individual'\n",
    "args.DATA_UNIT = f'l1o'\n",
    "\n",
    "BASE_path = f'{os.environ[\"HOME\"]}/new_mouse_dataset'\n",
    "PARCELS_path = f'{BASE_path}/parcels'\n",
    "ROI_path = (\n",
    "    f'{BASE_path}/roi-results-v3'\n",
    "    f'/{PARC_DESC}'\n",
    ")\n",
    "TS_path = f'{ROI_path}/roi_timeseries'\n",
    "ROI_RESULTS_path = (\n",
    "    f'{ROI_path}'\n",
    "    f'/graph-{args.GRAPH_DEF}/method-{args.GRAPH_METHOD}'\n",
    "    f'/threshold-{args.THRESHOLD}/edge-{args.EDGE_DEF}/density-{args.EDGE_DENSITY}'\n",
    "    f'/layer-{args.LAYER_DEF}/unit-{args.DATA_UNIT}'\n",
    ")\n",
    "GRAPH_path = f'{ROI_RESULTS_path}/graphs'\n",
    "os.system(f'mkdir -p {GRAPH_path}')\n",
    "SBM_path = f'{ROI_RESULTS_path}/model-fits'\n",
    "os.system(f'mkdir -p {SBM_path}')\n",
    "DIAG_path = f'{ROI_RESULTS_path}/diagnostics'\n",
    "os.system(f'mkdir -p {DIAG_path}')\n",
    "ESTIM_path = f'{ROI_RESULTS_path}/estimates'\n",
    "os.system(f'mkdir -p {ESTIM_path}/individual')\n",
    "os.system(f'mkdir -p {ESTIM_path}/group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sbm-nd-h'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.dc, args.sbm = False, 'h'\n",
    "args.nested = args.sbm == 'h'\n",
    "\n",
    "args.force_niter = 100000\n",
    "args.num_draws = int((1/2) * args.force_niter)\n",
    "\n",
    "args.epsilon = 0.4 # threshold KSD for convergence\n",
    "args.delta = np.ceil(args.force_niter / 100).astype(int)\n",
    "\n",
    "def sbm_name(args):\n",
    "    dc = f'dc' if args.dc else f'nd'\n",
    "    dc = f'' if args.sbm in ['a', 'm'] else dc\n",
    "    file = f'sbm-{dc}-{args.sbm}'\n",
    "    return file\n",
    "\n",
    "SBM = sbm_name(args)\n",
    "SBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph object, undirected, with 172 vertices and 2942 edges, 1 internal edge property, at 0x7f77394ade80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile = sorted(glob.glob(f'{GRAPH_path}/*', recursive=True))[0]\n",
    "g = gt.load_graph(gfile)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_partitions(args, indests_df):\n",
    "    all_bs_df = []\n",
    "    for idx, row in tqdm(indests_df.iterrows()):\n",
    "        bs = random.sample(\n",
    "            list(row['mode'].get_partitions().values()), \n",
    "            row['num_samples']\n",
    "        )\n",
    "        df = pd.DataFrame(dict(\n",
    "            sub=[row['boot']]*len(bs),\n",
    "            mode_id=[idx]*len(bs),\n",
    "            b=bs,\n",
    "        ))\n",
    "        all_bs_df += [df]\n",
    "        # all_bs += [\n",
    "        #   row['mode'].sample_partition(MLE=True) \n",
    "        #   for _ in range(row['num_samples'])\n",
    "        # ]\n",
    "    all_bs_df = pd.concat(all_bs_df).reset_index(drop=True)\n",
    "    return all_bs_df\n",
    "\n",
    "def sample_nested_partitions(args, indests_df):\n",
    "    all_bs_df = []\n",
    "    for idx, row in tqdm(indests_df.iterrows()):\n",
    "        bs = random.sample(\n",
    "            list(row['mode'].get_nested_partitions().values()), \n",
    "            row['num_samples']\n",
    "        )\n",
    "        # bs = [gt.nested_partition_clear_null(b) for b in bs]\n",
    "        df = pd.DataFrame(dict(\n",
    "            sub=[row['boot']]*len(bs),\n",
    "            mode_id=[idx]*len(bs),\n",
    "            b=bs,\n",
    "        ))\n",
    "        all_bs_df += [df]\n",
    "        # all_bs += [\n",
    "        #   row['mode'].sample_partition(MLE=True) \n",
    "        #   for _ in range(row['num_samples'])\n",
    "        # ]\n",
    "    all_bs_df = pd.concat(all_bs_df).reset_index(drop=True)\n",
    "    return all_bs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reduced_indiv_estim(args, indiv_file):\n",
    "    # load individual estimates\n",
    "    with open(indiv_file, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "        \n",
    "    # make output folder\n",
    "    match = re.search(r'sub-(?P<sub>[^_]+)_task-(?P<task>[^/]+)', indiv_file)\n",
    "    if match: sub, task = match.groups()\n",
    "    red_indiv_path = f'{ESTIM_path}/individual/sub-{sub}_task-{task}/partition-modes-reduced'\n",
    "    os.makedirs(red_indiv_path, exist_ok=True)\n",
    "\n",
    "    # sample partitions per mode\n",
    "    args.total_samples = 1000\n",
    "    df['num_samples'] = df['omega'].apply(lambda x: np.round(x * args.total_samples).astype(int) if x > 0.01 else 1)\n",
    "    if args.sbm in ['m', 'a', 'd']:\n",
    "        all_bs_df = sample_partitions(args, df)\n",
    "    if args.sbm in ['h']:\n",
    "        all_bs_df = sample_nested_partitions(args, df)\n",
    "        \n",
    "    # create the indiv_estim_df\n",
    "    red_df = []\n",
    "    for mode_id, group in all_bs_df.groupby('mode_id'):\n",
    "        mode = gt.PartitionModeState(group['b'], relabel=False, nested=args.nested, converge=False)\n",
    "        r = df[df['mode_id'] == mode_id].reset_index(drop=True)\n",
    "        row = pd.DataFrame(dict(\n",
    "            sub=[r['boot'][0]],\n",
    "            sbm=[r['sbm'][0]],\n",
    "            mode_id=[mode_id],\n",
    "            mode=[mode],\n",
    "            omega=[r['omega'][0]],\n",
    "            sigma=[r['sigma'][0]],\n",
    "        ))\n",
    "        red_df += [row]\n",
    "        # break\n",
    "    red_df = pd.concat(red_df).reset_index(drop=True)\n",
    "\n",
    "    # save the df\n",
    "    with open(f'{red_indiv_path}/{SBM}_desc-df.pkl', 'wb') as f:\n",
    "        pickle.dump(red_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_files = sorted(glob.glob(f'{ESTIM_path}/individual/sub-*/partition-modes/{SBM}_desc-df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 19.50it/s]\n",
      "11it [00:00, 32.04it/s]\n",
      "10it [00:00, 32.64it/s]\n",
      "8it [00:00, 14.12it/s]\n",
      "9it [00:00, 19.62it/s]\n",
      "11it [00:00, 18.56it/s]\n",
      "9it [00:00, 24.06it/s]\n",
      "11it [00:00, 34.76it/s]\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=10)(\n",
    "    delayed(create_reduced_indiv_estim)(args, indiv_file) \n",
    "    for indiv_file in (indiv_files)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
